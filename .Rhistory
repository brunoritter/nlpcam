html_node('ul') %>%
html_children() %>%
html_children() %>%
html_text()
solene <- which(grepl('Solene', text))
links_plenario <- links[-solene]
files <- c()
if(length(links_plenario) > 0) {
for (i in c(1:length(links_plenario))) {
file_name <- paste0(i,'_',day,'_',month,'_',year)
download.file(
links_plenario[i],
file_name,
mode = 'wb')
files <- append(files, file_name)
}}
return(files)
}
files <- pmap(search_grid, pdf_downloader)
initial.date <- '22/01/2019'
final.date <- '29/03/2019'
initial.date <- as.Date(initial.date, format)
format = '%d/%m/%Y'
initial.date <- as.Date(initial.date, format)
final.date <- as.Date(final.date, format)
search_grid <-
seq(initial.date,final.date, by = 'days') %>%
tibble() %>%
mutate(
day = day(.),
month = month(.),
year = year(.)
) %>%
select(-.)
initial.date <- '22/03/2019'
initial.date <- as.Date(initial.date, format)
final.date <- as.Date(final.date, format)
search_grid <-
seq(initial.date,final.date, by = 'days') %>%
tibble() %>%
mutate(
day = day(.),
month = month(.),
year = year(.)
) %>%
select(-.)
files <- pmap(search_grid, pdf_downloader)
unlist(files)
files <- unlist(files)
a <- pdf_downloader(27,3,2019)
day = 27
month = 3
year = 2019
url <- 'https://www.camara.leg.br/internet/plenario/notas/notas.asp'
query <- list('dia'= day,
'mes'= month,
'ano'= year)
response <- GET(url = url, query = query)
response_html <- content(response)
links <- response_html %>%
html_node('ul') %>%
html_children() %>%
html_children() %>%
html_children() %>%
html_attr('href')
text <- response_html %>%
html_node('ul') %>%
html_children() %>%
html_children() %>%
html_text()
solene <- which(grepl('Solene', text))
links_plenario <- links[-solene]
solene <- which(grepl('Solene', text))
solene
files[0]
files[-0]
files[1]
length(solene)
solene <- which(grepl('Solene', text))
if (length(solene) > 0) {
links_plenario <- links[-solene]
} else {
links_plenario <- links
}
pdf_downloader <- function(day, month, year) {
url <- 'https://www.camara.leg.br/internet/plenario/notas/notas.asp'
query <- list('dia'= day,
'mes'= month,
'ano'= year)
response <- GET(url = url, query = query)
response_html <- content(response)
links <- response_html %>%
html_node('ul') %>%
html_children() %>%
html_children() %>%
html_children() %>%
html_attr('href')
text <- response_html %>%
html_node('ul') %>%
html_children() %>%
html_children() %>%
html_text()
solene <- which(grepl('Solene', text))
if (length(solene) > 0) {
links_plenario <- links[-solene]
} else {
links_plenario <- links
}
files <- c()
if(length(links_plenario) > 0) {
for (i in c(1:length(links_plenario))) {
file_name <- paste0(i,'_',day,'_',month,'_',year)
download.file(
links_plenario[i],
file_name,
mode = 'wb')
files <- append(files, file_name)
}}
return(files)
}
initial.date <- '22/03/2019'
final.date <- '29/03/2019'
format = '%d/%m/%Y'
initial.date <- as.Date(initial.date, format)
final.date <- as.Date(final.date, format)
search_grid <-
seq(initial.date,final.date, by = 'days') %>%
tibble() %>%
mutate(
day = day(.),
month = month(.),
year = year(.)
) %>%
select(-.)
files <- pmap(search_grid, pdf_downloader) %>% unlist()
data <- map_df(files, pdf_parser)
pdf_parser <- function(file) {
pdf <- pdf_text(file)
date <-
stri_extract(regex = '[\\d]{2}\\/[\\d]{2}\\/[\\d]{4}', pdf[1])
clean <- str_replace(pdf, '.*\\\r', '')
clean <- paste(clean, collapse = ' ')
clean <- gsub('\\n|\\r', ' ', clean)
citations <-
unlist(strsplit(clean, '(?<=.)(?= (O SR\\.|A SRA\\.) .*\\(.*\\) - )', perl = T))
citations <- tibble(citations)
citations$identifier <-
str_extract(citations$citations, ' (O SR\\.|A SRA\\.) .*\\(.*\\) - ')
citations$gender <-
ifelse(grepl(
citations$identifier,
pattern = 'SR\\.',
ignore.case = F
),
'M',
'F')
citations$name <-
gsub('( O SR\\. | A SRA\\. )(.*)( \\(.*)', '\\2', citations$identifier)
citations$president <- ifelse(citations$name == 'PRESIDENTE', 1, 0)
citations$name <- ifelse(citations$name == 'PRESIDENTE',
sub('(.*\\()(.*)(\\..*)', '\\2', x = citations$identifier) %>% toupper(),
citations$name)
session_type <-
str_extract(citations$citations[1], '(?<=\\()SESSÃO.*?(?=\\))')
session_n <-
unlist(str_extract_all(citations$citations[1], '[\\d]+ª SESSÃO'))[2] %>% gsub(pattern = 'ª SESSÃO', replacement =  '')
session_legislature <-
str_extract(citations$citations[1] , '[\\d]+(?=ª LEGISLATURA)')
citations$citations <-
gsub('( (O SR\\.|A SRA\\.) .*\\(.*\\) - )(.*)',
'\\3',
citations$citations)
session_start_time <-
str_extract_all(pattern = '(?<=Às )[\\d]{2}|[\\d]{2}(?= minutos)', string =  citations$citations[1]) %>% unlist() %>% paste(collapse = ':')
session_end_time <-
str_extract_all(pattern = '(?<=às )[\\d]{2}|[\\d]{2}(?= minutos)', string =  citations$citations[nrow(citations)]) %>% unlist() %>% paste(collapse = ':')
citations <-
citations %>% select(name, president, gender, quote = citations) %>% filter(!is.na(name))
citations$date <- date
citations$session_type <- session_type
citations$session_n <- session_n
citations$session_start_time <- session_start_time
citations$session_end_time <- session_end_time
citations$legislature <- session_legislature
citations$word_count <- str_count(citations$quote, '\\S+')
citations$sequence <- c(1:nrow(citations))
return(citations)
}
data <- map_df(files, pdf_parser)
View(data)
get_data <- function(initial.date, final.date, format = '%d/%m/%Y') {
initial.date <- as.Date(initial.date, format)
final.date <- as.Date(final.date, format)
search_grid <-
seq(initial.date,final.date, by = 'days') %>%
tibble() %>%
mutate(
day = day(.),
month = month(.),
year = year(.)
) %>%
select(-.)
files <- pmap(search_grid, pdf_downloader) %>% unlist()
data <- map_df(files, pdf_parser)
return(data)
}
teste <- get_data('15/01/2019', '29/03/2019')
teste <- get_data('15/01/2019', '29/03/2019')
teste <- get_data('15/03/2019', '29/03/2019')
teste <- get_data('15/03/2019', '29/03/2019')
teste <- get_data('15/03/2019', '29/03/2019')
seq_along(links_plenario)
teste <- get_data('15/03/2019', '29/03/2019')
View(teste)
pdf_downloader <- function(day, month, year) {
url <- 'https://www.camara.leg.br/internet/plenario/notas/notas.asp'
query <- list('dia'= day,
'mes'= month,
'ano'= year)
response <- GET(url = url, query = query)
response_html <- content(response)
links <- response_html %>%
html_node('ul') %>%
html_children() %>%
html_children() %>%
html_children() %>%
html_attr('href')
text <- response_html %>%
html_node('ul') %>%
html_children() %>%
html_children() %>%
html_text()
solene <- which(grepl('Solene', text))
if (length(solene) > 0) {
links_plenario <- links[-solene]
} else {
links_plenario <- links
}
files <- c()
if(length(links_plenario) > 0) {
for (i in seq_along(links_plenario)) {
file_name <- paste0(i,'_',day,'_',month,'_',year)
download.file(
links_plenario[i],
file_name,
mode = 'wb')
files <- append(files, file_name)
}}
return(files)
}
pdf_parser <- function(file) {
pdf <- pdf_text(file)
date <-
stri_extract(regex = '[\\d]{2}\\/[\\d]{2}\\/[\\d]{4}', pdf[1])
clean <- str_replace(pdf, '.*\\\r', '')
clean <- paste(clean, collapse = ' ')
clean <- gsub('\\n|\\r', ' ', clean)
citations <-
unlist(strsplit(clean, '(?<=.)(?= (O SR\\.|A SRA\\.) .*\\(.*\\) - )', perl = T))
citations <- tibble(citations)
citations$identifier <-
str_extract(citations$citations, ' (O SR\\.|A SRA\\.) .*\\(.*\\) - ')
citations$gender <-
ifelse(grepl(
citations$identifier,
pattern = 'SR\\.',
ignore.case = F
),
'M',
'F')
citations$name <-
gsub('( O SR\\. | A SRA\\. )(.*)( \\(.*)', '\\2', citations$identifier)
citations$president <- ifelse(citations$name == 'PRESIDENTE', 1, 0)
citations$name <- ifelse(citations$name == 'PRESIDENTE',
sub('(.*\\()(.*)(\\..*)', '\\2', x = citations$identifier) %>% toupper(),
citations$name)
session_type <-
str_extract(citations$citations[1], '(?<=\\()SESSÃO.*?(?=\\))')
session_n <-
unlist(str_extract_all(citations$citations[1], '[\\d]+ª SESSÃO'))[2] %>% gsub(pattern = 'ª SESSÃO', replacement =  '')
session_legislature <-
str_extract(citations$citations[1] , '[\\d]+(?=ª LEGISLATURA)')
citations$citations <-
gsub('( (O SR\\.|A SRA\\.) .*\\(.*\\) - )(.*)',
'\\3',
citations$citations)
session_start_time <-
str_extract_all(pattern = '(?<=Às )[\\d]{2}|[\\d]{2}(?= minutos)', string =  citations$citations[1]) %>% unlist() %>% paste(collapse = ':')
session_end_time <-
str_extract_all(pattern = '(?<=às )[\\d]{2}|[\\d]{2}(?= minutos)', string =  citations$citations[nrow(citations)]) %>% unlist() %>% paste(collapse = ':')
citations <-
citations %>% select(name, president, gender, quote = citations) %>% filter(!is.na(name))
citations$date <- date
citations$session_type <- session_type
citations$session_n <- session_n
citations$session_start_time <- session_start_time
citations$session_end_time <- session_end_time
citations$legislature <- session_legislature
citations$word_count <- str_count(citations$quote, '\\S+')
citations$sequence <- c(1:nrow(citations))
return(citations)
}
get_data <- function(initial.date, final.date, format = '%d/%m/%Y') {
initial.date <- as.Date(initial.date, format)
final.date <- as.Date(final.date, format)
search_grid <-
seq(initial.date,final.date, by = 'days') %>%
tibble() %>%
mutate(
day = day(.),
month = month(.),
year = year(.)
) %>%
select(-.)
files <- pmap(search_grid, pdf_downloader) %>% unlist()
data <- map_df(files, pdf_parser)
return(data)
}
dados <- get_data('01/03/2019', '29/03/2019')
View(dados)
file <- pdf_text('2_20_3_2019')
pdf <- pdf_text('2_20_3_2019')
date <-
stri_extract(regex = '[\\d]{2}\\/[\\d]{2}\\/[\\d]{4}', pdf[1])
clean <- str_replace(pdf, '.*\\\r', '')
clean <- paste(clean, collapse = ' ')
clean <- gsub('\\n|\\r', ' ', clean)
citations <-
unlist(strsplit(clean, '(?<=.)(?= (O SR\\.|A SRA\\.) .*\\(.*\\) - )', perl = T))
citations <- tibble(citations)
citations$identifier <-
str_extract(citations$citations, ' (O SR\\.|A SRA\\.) .*\\(.*\\) - ')
citations$gender <-
ifelse(grepl(
citations$identifier,
pattern = 'SR\\.',
ignore.case = F
),
'M',
'F')
citations$name <-
gsub('( O SR\\. | A SRA\\. )(.*)( \\(.*)', '\\2', citations$identifier)
citations$president <- ifelse(citations$name == 'PRESIDENTE', 1, 0)
citations$name <- ifelse(citations$name == 'PRESIDENTE',
sub('(.*\\()(.*)(\\..*)', '\\2', x = citations$identifier) %>% toupper(),
citations$name)
session_type <-
str_extract(citations$citations[1], '(?<=\\()SESSÃO.*?(?=\\))')
session_n <-
unlist(str_extract_all(citations$citations[1], '[\\d]+ª SESSÃO'))[2] %>% gsub(pattern = 'ª SESSÃO', replacement =  '')
session_legislature <-
str_extract(citations$citations[1] , '[\\d]+(?=ª LEGISLATURA)')
citations$citations <-
gsub('( (O SR\\.|A SRA\\.) .*\\(.*\\) - )(.*)',
'\\3',
citations$citations)
session_start_time <-
str_extract_all(pattern = '(?<=Às )[\\d]+|[\\d]+(?= minutos)', string =  citations$citations[1]) %>% unlist() %>% paste(collapse = ':')
session_end_time <-
str_extract_all(pattern = '(?<=às )[\\d]+|[\\d]+(?= minutos)', string =  citations$citations[nrow(citations)]) %>% unlist() %>% paste(collapse = ':')
pdf[1]
citations[1]
citations$citations[1]
citations$citations[319]
session_end_time <-
str_extract_all(pattern = '(?<=Encerra-se a sessão às )[\\d]+|[\\d]+(?= minutos)', string =  citations$citations[nrow(citations)]) %>% unlist() %>% paste(collapse = ':')
tempfile
tempfile()
pdf_downloader <- function(day, month, year) {
url <- 'https://www.camara.leg.br/internet/plenario/notas/notas.asp'
query <- list('dia'= day,
'mes'= month,
'ano'= year)
response <- httr::GET(url = url, query = query)
response_html <- httr::content(response)
links <- response_html %>%
rvest::html_node('ul') %>%
rvest::html_children() %>%
rvest::html_children() %>%
rvest::html_children() %>%
rvest::html_attr('href')
text <- response_html %>%
rvest::html_node('ul') %>%
rvest::html_children() %>%
rvest::html_children() %>%
rvest::html_text()
solene <- which(grepl('Solene', text))
if (length(solene) > 0) {
links_plenario <- links[-solene]
} else {
links_plenario <- links
}
files <- c()
if(length(links_plenario) > 0) {
for (i in seq_along(links_plenario)) {
file_name <- paste0(i,'_',day,'_',month,'_',year)
download.file(
links_plenario[i],
file_name,
mode = 'wb')
files <- append(files, file_name)
}}
return(files)
}
pdf_parser <- function(file) {
pdf <- pdftools::pdf_text(file)
date <-
stringr::str_extract(pdf[1], '[\\d]{2}\\/[\\d]{2}\\/[\\d]{4}')
clean <- stringr::str_replace(pdf, '.*\\\r', '')
clean <- paste(clean, collapse = ' ')
clean <- gsub('\\n|\\r', ' ', clean)
citations <-
unlist(strsplit(clean, '(?<=.)(?= (O SR\\.|A SRA\\.) .*\\(.*\\) - )', perl = T))
citations <- dplyr::tibble(citations)
citations$identifier <-
stringr::str_extract(citations$citations, ' (O SR\\.|A SRA\\.) .*\\(.*\\) - ')
citations$gender <-
ifelse(grepl(
citations$identifier,
pattern = 'SR\\.',
ignore.case = F
),
'M',
'F')
citations$name <-
gsub('( O SR\\. | A SRA\\. )(.*)( \\(.*)', '\\2', citations$identifier)
citations$president <- ifelse(citations$name == 'PRESIDENTE', 1, 0)
citations$name <- ifelse(citations$name == 'PRESIDENTE',
sub('(.*\\()(.*)(\\..*)', '\\2', x = citations$identifier) %>% toupper(),
citations$name)
session_type <-
stringr::str_extract(citations$citations[1], '(?<=\\()SESSÃO.*?(?=\\))')
session_n <-
unlist(str_extract_all(citations$citations[1], '[\\d]+ª SESSÃO'))[2] %>% gsub(pattern = 'ª SESSÃO', replacement =  '')
session_legislature <-
stringr::str_extract(citations$citations[1] , '[\\d]+(?=ª LEGISLATURA)')
citations$citations <-
gsub('( (O SR\\.|A SRA\\.) .*\\(.*\\) - )(.*)',
'\\3',
citations$citations)
session_start_time <-
stringr::str_extract_all(pattern = '(?<=Às )[\\d]+|[\\d]+(?= minutos)', string =  citations$citations[1]) %>% unlist() %>% paste(collapse = ':')
session_end_time <-
stringr::str_extract_all(pattern = '(?<=Encerra-se a sessão às )[\\d]+|[\\d]+(?= minutos)', string =  citations$citations[nrow(citations)]) %>% unlist() %>% paste(collapse = ':')
citations <-
citations %>% dplyr::select(name, president, gender, quote = citations) %>% dplyr::filter(!is.na(name))
citations$date <- date
citations$session_type <- session_type
citations$session_n <- session_n
citations$session_start_time <- session_start_time
citations$session_end_time <- session_end_time
citations$legislature <- session_legislature
citations$word_count <- stringr::str_count(citations$quote, '\\S+')
citations$sequence <- c(1:nrow(citations))
return(citations)
}
get_data <- function(initial.date, final.date, format = '%d/%m/%Y') {
initial.date <- as.Date(initial.date, format)
final.date <- as.Date(final.date, format)
search_grid <-
seq(initial.date,final.date, by = 'days') %>%
dplyr::tibble() %>%
dplyr::mutate(
day = day(.),
month = month(.),
year = year(.)
) %>%
dplyr::select(-.)
files <- purrr::pmap(search_grid, pdf_downloader) %>% unlist()
data <- purrr::map_df(files, pdf_parser)
return(data)
}
a <- get_data('20/04/2019', '20/04/2019')
a <- get_data('20/03/2019', '20/03/2019')
View(a)
View(a)
getwd()
setwd('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam/R/')
install.packages('Roxygen2')
install.packages('roxygen2')
library(roxygen2)
document()
library(devtools)
document()
getwd()
setwd('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam/')
document()
setwd('C:/Users/ritte/Documents/GitHub/NLP-camara/')
document()
setwd('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam/')
document(pgk = 'nlpcam')
document('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam/')
document('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam')
document('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam/R')
dLOAD_ALL('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam/R')
load_all('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam/R')
load_all('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam')
load_all('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam')
load_all('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam/R')
load_all('C:/Users/ritte/Documents/GitHub/NLP-camara/nlpcam/R')
create()
create_package()
create_package('C:/Users/ritte/Documents/GitHub/NLP-camara/)
create_package('C:/Users/ritte/Documents/GitHub/NLP-camara/')
create_package('C:/Users/ritte/Documents/GitHub/nlpcam')
load_all('C:/Users/ritte/Documents/GitHub/nlpcam/')
load_all('C:/Users/ritte/Documents/GitHub/nlpcam/')
load_all('C:/Users/ritte/Documents/GitHub/nlpcam/')
warnings()
setwd('~/GitHub/nlpcam/')
document()
build()
